# Auto-generated by CodegenAgent
from __future__ import annotations

from typing import Any, Dict

from core.agents_base import Agent, AgentResult
from core.models import EmotionalState, EmotionDelta, ConversationContext
from core.memory import MemoryEngine
from core.llm_provider import LLMProvider


class CustomAgentBBFB398E(Agent):
    """
    Agente personalizzato per eseguire compiti specifici
    (Generato automaticamente da CodegenAgent.)
    """

    name = "custom_agent_bbfb398e"
    description = "Agente personalizzato per eseguire compiti specifici"

    SYSTEM_PROMPT = """Esegui azione personalizzata con parametri: $params"""

    def _run_impl(
        self,
        input_payload: Dict[str, Any],
        context: ConversationContext,
        memory: MemoryEngine,
        llm: LLMProvider,
        emotional_state: EmotionalState,
    ) -> AgentResult:
        # Recupera il messaggio utente principale:
        # 1) da input_payload["user_message"]
        # 2) altrimenti dall'ultimo messaggio USER nel contesto, se disponibile.
        user_message = input_payload.get("user_message") or (
            context.messages[-1].content if context.messages else ""
        )

        if self.SYSTEM_PROMPT:
            from core.models import Message, MessageRole  # import locale per evitare cicli

            messages = [
                Message(role=MessageRole.USER, content=user_message),
            ]
            llm_output = llm.generate(
                system_prompt=self.SYSTEM_PROMPT,
                messages=messages,
                max_tokens=512,
            )
            text = llm_output
        else:
            text = (
                "Sono un agent generato automaticamente. "
                "Non ho ancora una logica specifica oltre a questo messaggio di placeholder."
            )

        output = {
            "user_visible_message": text,
            "stop_for_user_input": False,
        }
        delta = EmotionDelta()
        return AgentResult(output_payload=output, emotion_delta=delta)
